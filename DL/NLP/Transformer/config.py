N_LAYERS = 4
D_MODEL = 256
N_HEADS = 8
UNITS = 256
DROP = 0.1
STD_BS = 16
SET_BS = 128
# BS = BATCH_SIZE
EPOCHS = 1000
MAX_SENTENCE_LENGTH = 20
SAV_P = 5
# SAVE_PERIOD
TGT_VOC_SIZE = 1024 * 4
DATA_BUFFER_SIZE = 10240
# TOK_PATH = 'Save/Chat/tokenizer'
TOK_PATH = 'Save/Translate/tokenizer'
# WGT_PATH = 'Save/Chat/bot_4'
WGT_PATH = 'Save/Translate/bot_4'
STD_TCOUNT = 625
SET_TCOUNT = 20000
# TCOUNT = TRAIN_COUNT
STD_TRAIN_STEP = 6
SET_TRAIN_STEP = int(STD_TRAIN_STEP * (SET_TCOUNT / STD_TCOUNT) / (SET_BS / STD_BS))
WARM_UP_EPOCH = int(SET_TRAIN_STEP * 0.5)
