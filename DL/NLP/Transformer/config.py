N_LAYERS = 4
D_MODEL = 128
N_HEADS = 8
UNITS = 128
DROP = 0.1
BSIZE = 128
# BATCH_SIZE
EPOCHS = 1000
MAX_SENTENCE_LENGTH = 20
SAV_P = 5
# SAVE_PERIOD
TGT_VOC_SIZE = 1024 * 4
DATA_BUFFER_SIZE = 10240
# TOK_PATH = 'Save/Chat/tokenizer'
TOK_PATH = 'Save/Translate/tokenizer'
# WGT_PATH = 'Save/Chat/bot_4'
WGT_PATH = 'Save/Translate/bot_4'
STD_TCOUNT = 5000
SET_TCOUNT = 10000
# TCOUNT = TRAIN_COUNT
STD_TRAIN_EPOCH = 6
SET_TRAIN_EPOCH = int(STD_TRAIN_EPOCH * (SET_TCOUNT / STD_TCOUNT))
WARM_UP_EPOCH = int(SET_TRAIN_EPOCH / 2)
