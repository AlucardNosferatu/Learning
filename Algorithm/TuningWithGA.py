# -*- coding: utf-8 -*-
"""
Created on Sat Aug 31 16:24:31 2019

@author: 16413
"""

from __future__ import print_function
from keras.datasets import cifar10
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.utils import np_utils
import numpy as np
import geatpy as gp


def trainloop(params_ga, X_train, X_test, Y_train, Y_test, nb_classes, nb_epoch, batch_size):
    layers_def = [
        'conv',
        #        'conv',
        'pool',
        'dropout',
        'conv',
        #        'conv',
        'pool',
        'dropout',
        'flat',
        #        'dense',
        'dropout',
        'dense'
    ]
    params = [
        [params_ga[0], 3, 3, 'same'],
        #        [32,3,3,'valid'],
        [2, 2],
        [0.25],
        [params_ga[1], 3, 3, 'same'],
        #        [64,3,3,'valid'],
        [2, 2],
        [0.25],
        [],
        #            [512],
        [0.5],
        [nb_classes]
    ]

    model = Sequential()

    for index in range(0, len(layers_def)):
        if index == 0:
            if layers_def[index] == 'conv':
                model.add(
                    Convolution2D(params[index][0], params[index][1], params[index][2], border_mode=params[index][3],
                                  input_shape=X_train.shape[1:]))
                model.add(Activation('relu'))
        elif index == len(layers_def) - 1:
            if layers_def[index] == 'dense':
                model.add(Dense(params[index][0]))
                model.add(Activation('softmax'))
        else:
            if layers_def[index] == 'conv':
                model.add(
                    Convolution2D(params[index][0], params[index][1], params[index][2], border_mode=params[index][3]))
                model.add(Activation('relu'))
            elif layers_def[index] == 'pool':
                model.add(MaxPooling2D(pool_size=(params[index][0], params[index][1])))
            elif layers_def[index] == 'dropout':
                model.add(Dropout(params[index][0]))
            elif layers_def[index] == 'flat':
                model.add(Flatten())
            elif layers_def[index] == 'dense':
                model.add(Dense(params[index][0]))
                model.add(Activation('relu'))

    # plot_model(model, to_file='cifar10-cnn.png')

    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    X_train /= 255
    X_test /= 255

    # 这将做预处理和实时数据增加
    datagen = ImageDataGenerator(
        featurewise_center=False,  # 在数据集上将输入平均值设置为0
        samplewise_center=False,  # 将每个样本均值设置为0
        featurewise_std_normalization=False,  # 将输入除以数据集的std
        samplewise_std_normalization=False,  # 将每个输入除以其std
        zca_whitening=False,  # 应用ZCA白化
        rotation_range=0,  # 在一个范围下随机旋转图像(degrees, 0 to 180)
        width_shift_range=0.1,  # 水平随机移位图像（总宽度的分数）
        height_shift_range=0.1,  # 随机地垂直移动图像（总高度的分数）
        horizontal_flip=True,  # 随机翻转图像
        vertical_flip=False)  # 随机翻转图像
    # 计算特征方向归一化所需的数量
    # (std, mean, and principal components if ZCA whitening is applied)
    datagen.fit(X_train)
    # fit the model on the batches generated by datagen.flow()
    history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),
                                  samples_per_epoch=X_train.shape[0], nb_epoch=nb_epoch,
                                  validation_data=(X_test, Y_test))
    history = history.history
    #    acc=np.array(history['acc'])
    return np.array(history['loss'])


def aim(Phen):
    Phen = Phen.tolist()

    batch_size = 64
    nb_classes = 10
    nb_epoch = 3

    # input image dimensions
    # the CIFAR10 images are RGB

    # the data, shuffled and split between train and test sets
    (X_train, y_train), (X_test, y_test) = cifar10.load_data()
    print('X_train shape:', X_train.shape)
    print(X_train.shape[0], 'train samples')
    print(X_test.shape[0], 'test samples')

    Y_train = np_utils.to_categorical(y_train, nb_classes)
    Y_test = np_utils.to_categorical(y_test, nb_classes)

    losses = []
    for index in range(0, len(Phen)):
        loss = trainloop(Phen[index], X_train, X_test, Y_train, Y_test, nb_classes, nb_epoch, batch_size)
        loss = sum(loss)
        losses.append(loss)
    length = len(losses)
    losses = np.array(losses)
    losses.shape = (length, 1)
    return losses


x1_i = [16, 128]
x2_i = [16, 128]
b_x1 = [1, 1]
b_x2 = [1, 1]

ranges = np.vstack([x1_i, x2_i]).T
borders = np.vstack([b_x1, b_x2]).T
varTypes = np.array([1, 1])

Encoding = 'BG'
codes = [1, 1]
precisions = [0, 0]
scales = [0, 0]

FieldD = gp.crtfld(Encoding, varTypes, ranges, borders, precisions, codes, scales)

NIND = 20
MAXGEN = 10
maxormins = [1]  # 1 means minimization
selectStyle = 'sus'
recStyle = 'xovdp'
mutStyle = 'mutbin'
pc = 0.9
pm = 1
Lind = int(np.sum(FieldD[0, :]))
obj_trace = np.zeros((MAXGEN, 2))
var_trace = np.zeros((MAXGEN, Lind))

Chrom = gp.crtpc(Encoding, NIND, FieldD)
variable = gp.bs2int(Chrom, FieldD)
variable = variable.astype(int)
ObjV = aim(variable)

best_ind = np.argmin(ObjV)

for gen in range(MAXGEN):
    FitnV = gp.ranking(maxormins * ObjV)

    SelCh = Chrom[gp.selecting(selectStyle, FitnV, NIND - 1), :]
    SelCh = gp.recombin(recStyle, SelCh, pc)
    SelCh = gp.mutate(mutStyle, Encoding, SelCh, pm)

    Chrom = np.vstack([Chrom[best_ind, :], SelCh])

    Phen = gp.bs2int(Chrom, FieldD)
    Phen = Phen.astype(int)
    ObjV = aim(Phen)
    obj_trace[gen, 1] = ObjV[best_ind]
    var_trace[gen, :] = Chrom[best_ind, :]

gp.trcplot(obj_trace, [['我就是试试', '也没指望有啥结果']])
best_gen = np.argmin(obj_trace[:, [1]])
print('最好效果', obj_trace[best_gen, 1])
variable = gp.bs2int(var_trace[[best_gen], :], FieldD)
variable = variable.astype(int)
print('最好变量:')
for i in range(variable.shape[1]):
    print('x' + str(i) + '=', variable[0, i])
